{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ffb97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 5.2.5\n",
    "# 学習済みWord2Vecデータのロード\n",
    "\n",
    "import gensim\n",
    "\n",
    "model = gensim.models.Word2Vec.load(\"ja.bin\")\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a4b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 5.2.6\n",
    "# 学習済みWord2Vecの挙動を調べる\n",
    "\n",
    "# 「世間」の特徴量ベクトルを調べる\n",
    "print(\"「世間」の特徴量ベクトル\")\n",
    "print(model.wv[\"世間\"])\n",
    "\n",
    "# 「世間」の類似語を調べる\n",
    "print()\n",
    "print(\"「世間」の類似語\")\n",
    "for item, value in model.wv.most_similar(\"世間\"):\n",
    "    print(item, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79771243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 5.2.6\n",
    "# 学習済み Word2Vec の挙動を調べる\n",
    "#\n",
    "# 目的:\n",
    "#   - 学習済みベクトル空間における語「世間」の分布表現（埋め込みベクトル）を確認し、\n",
    "#     余弦類似度に基づく近傍語（most_similar）を一覧します。\n",
    "#\n",
    "# 前提:\n",
    "#   - `model` は gensim の Word2Vec もしくは KeyedVectors を既にロード済みであること。\n",
    "#     * gensim 4 系では、語ベクトル操作は `model.wv` (KeyedVectors) 経由で行います。\n",
    "#   - ベクトルは学習目的（CBOW/Skip-gram with Negative Sampling）によりスケール不定です。\n",
    "#     そのため語間の「近さ」の評価にはノルムに依存しない余弦類似度が一般的に用いられます。\n",
    "#\n",
    "# 注意:\n",
    "#   - 語彙外 (OOV) の場合は `model.wv['世間']` や `most_similar(\"世間\")` で KeyError が発生します。\n",
    "#     日本語では前処理（分かち書き・NFKC 正規化・表記ゆれ吸収）に強く依存するため、\n",
    "#     実運用では「語が辞書に存在するか」を事前に確認することを推奨します。\n",
    "#       例) `'世間' in model.wv.key_to_index`\n",
    "#\n",
    "# 補足（理論メモ）:\n",
    "#   - `most_similar` は内部で正規化済みベクトルを用い、(実質) 余弦類似度に基づく上位近傍を返します。\n",
    "#   - 近傍語は「意味が似ている語」に限らず、同一文脈で出現しやすい共起語・主題語が混在します。\n",
    "#     これは分布仮説（“You shall know a word by the company it keeps”）に基づく自然な挙動です。\n",
    "\n",
    "# 「世間」の特徴量ベクトルを調べる（非正規化ベクトルの生値を表示します）\n",
    "print(\"「世間」の特徴量ベクトル\")\n",
    "print(model.wv[\"世間\"])  # OOV の場合は KeyError。実運用では事前チェックを推奨。\n",
    "\n",
    "# 「世間」の類似語を調べる（余弦類似度に基づく上位近傍を表示します）\n",
    "print()\n",
    "print(\"「世間」の類似語\")\n",
    "for item, value in model.wv.most_similar(\"世間\"):\n",
    "    # value は [-1, 1] 程度のスコア（余弦類似度相当）。1 に近いほど類似と解釈します。\n",
    "    print(item, value)\n",
    "\n",
    "# 参考（任意・コメントアウト例）:\n",
    "# # OOV を安全に扱う簡易ガード\n",
    "# token = '世間'\n",
    "# if token in model.wv.key_to_index:\n",
    "#     vec = model.wv[token]\n",
    "#     print(f'vector_size={model.wv.vector_size}, norm={np.linalg.norm(vec):.4f}')\n",
    "#     for w, s in model.wv.most_similar(token, topn=10):\n",
    "#         print(w, f'{s:.3f}')\n",
    "# else:\n",
    "#     print(f\"[OOV] '{token}' は語彙に存在しません。前処理・表記ゆれを確認してください。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6f96ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 5.2.7\n",
    "# 「日本」→「東京」に対応する「フランス」→「X」をベクトル類推で求める\n",
    "#\n",
    "# 理論メモ:\n",
    "# - Word2Vec の類推は 3CosAdd（Mikolov, 2013）の基準で求めるのが一般的。\n",
    "#   目的は、v(X) ≈ v(東京) - v(日本) + v(フランス) を満たす語 X を\n",
    "#   余弦類似度 cos(v(X), 目標ベクトル) が最大となるように探索すること。\n",
    "# - gensim の `most_similar(positive=[...], negative=[...])` は内部で\n",
    "#   3CosAdd を実装しており、余弦類似度トップ N を返す。\n",
    "# - 3CosMul（掛け算版）もあり、頻度バイアスが軽減されるケースがある。\n",
    "# - 注意: OOV（語彙外）・表記ゆれ・分かち書きに強く依存するため、\n",
    "#         語彙に含まれるかを必ず事前に確認すること。\n",
    "#\n",
    "# 使い方:\n",
    "# - `model` は gensim の Word2Vec/KeyedVectors をロード済みである前提。\n",
    "# - トップ候補を `x_hat` として表示する。\n",
    "\n",
    "# 入力語（正例=足し算 / 負例=引き算）\n",
    "positive = [\"東京\", \"フランス\"]\n",
    "negative = [\"日本\"]\n",
    "\n",
    "# 事前チェック: 語彙外(OOV)がないか\n",
    "oov = [w for w in (positive + negative) if w not in model.wv.key_to_index]\n",
    "if oov:\n",
    "    print(f\"[OOV] モデル語彙に存在しない語: {oov}\")\n",
    "else:\n",
    "    # 1) 3CosAdd（標準）: most_similar\n",
    "    results_add = model.wv.most_similar(positive=positive, negative=negative, topn=10)\n",
    "\n",
    "    # 2) 明示ベクトル演算（確認用）: v = v(東京) - v(日本) + v(フランス)\n",
    "    target_vec = model.wv[\"東京\"] - model.wv[\"日本\"] + model.wv[\"フランス\"]\n",
    "    results_vec = model.wv.similar_by_vector(target_vec, topn=10)\n",
    "\n",
    "    # 3) 3CosMul（参考）: 頻度バイアスを抑えたい場合に試す\n",
    "    #    ※ コーパスにより挙動が異なるため、Add/Vec と結果が違うことがある\n",
    "    results_mul = model.wv.most_similar_cosmul(\n",
    "        positive=positive, negative=negative, topn=10\n",
    "    )\n",
    "\n",
    "    # 結果表示（トップ候補が推定 X）\n",
    "    print(\"=== 3CosAdd (most_similar) の上位候補 ===\")\n",
    "    for w, s in results_add:\n",
    "        print(f\"{w}\\t{s:.4f}\")\n",
    "    x_hat = results_add[0][0]\n",
    "    print(f\"\\n推定 X (Add): {x_hat}\")\n",
    "\n",
    "    print(\"\\n=== 明示ベクトル演算 similar_by_vector の上位候補 ===\")\n",
    "    for w, s in results_vec:\n",
    "        print(f\"{w}\\t{s:.4f}\")\n",
    "    x_hat_vec = results_vec[0][0]\n",
    "    print(f\"\\n推定 X (Vec): {x_hat_vec}\")\n",
    "\n",
    "    print(\"\\n=== 3CosMul (most_similar_cosmul) の上位候補 ===\")\n",
    "    for w, s in results_mul:\n",
    "        print(f\"{w}\\t{s:.4f}\")\n",
    "    x_hat_mul = results_mul[0][0]\n",
    "    print(f\"\\n推定 X (Mul): {x_hat_mul}\")\n",
    "\n",
    "    # 補足:\n",
    "    # - 3つの手法で推定 X が一致しない場合は、学習コーパスのドメイン/規模、前処理、品詞の混在、\n",
    "    #   語の多義性の影響が考えられる。タスクに合わせて正規化や語彙統一を見直すと良い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f834cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 5.2.8\n",
    "# 「男」→「女」に対応する「Y」→「妻」をベクトル類推で求める\n",
    "#\n",
    "# 理論メモ:\n",
    "# - Word2Vec のアナロジー（類推）は 3CosAdd（Mikolov, 2013）を用いるのが一般的。\n",
    "#   ここでは v(Y) ≈ v(妻) + v(男) − v(女) を満たす語 Y を，\n",
    "#   余弦類似度 cos(v(Y), v(妻)+v(男)−v(女)) が最大となるよう探索する。\n",
    "# - gensim の `most_similar(positive=[...], negative=[...])` は 3CosAdd を内部実装している。\n",
    "# - 品詞や表記ゆれ，分かち書き（Janome/MeCab など）で語彙が一致しないと OOV（語彙外）になるため，\n",
    "#   事前に語彙確認を行う。\n",
    "# - 社会的バイアスに依存する結果が出ることがある（注意: 学習コーパスに依存）。\n",
    "#\n",
    "# 前提:\n",
    "# - 変数 `model` は gensim の Word2Vec/KeyedVectors をロード済み。\n",
    "#   例: `from gensim.models import KeyedVectors; model = KeyedVectors.load(\"ja.kv\")`\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def check_oov(words: List[str]) -> List[str]:\n",
    "    \"\"\"語彙外(OOV)の単語を列挙するユーティリティ。\"\"\"\n",
    "    return [w for w in words if w not in model.wv.key_to_index]\n",
    "\n",
    "\n",
    "def print_results(title: str, pairs: List[Tuple[str, float]], topn: int = 10) -> None:\n",
    "    \"\"\"(語, 類似度) のリストを整形出力。\"\"\"\n",
    "    print(f\"\\n=== {title} 上位{topn} ===\")\n",
    "    for w, s in pairs[:topn]:\n",
    "        print(f\"{w}\\t{s:.4f}\")\n",
    "\n",
    "\n",
    "# 入力語（正例=足し算 / 負例=引き算）\n",
    "positive = [\"妻\", \"男\"]\n",
    "negative = [\"女\"]\n",
    "\n",
    "# 1) OOV チェック\n",
    "need = positive + negative\n",
    "oov = check_oov(need)\n",
    "if oov:\n",
    "    print(f\"[OOV] モデル語彙に存在しない語が含まれています: {oov}\")\n",
    "else:\n",
    "    # 2) 3CosAdd（標準）: most_similar\n",
    "    results_add = model.wv.most_similar(positive=positive, negative=negative, topn=10)\n",
    "\n",
    "    # 3) 明示ベクトル演算（検算用）: v = v(妻) + v(男) − v(女)\n",
    "    target_vec = model.wv[\"妻\"] + model.wv[\"男\"] - model.wv[\"女\"]\n",
    "    results_vec = model.wv.similar_by_vector(target_vec, topn=10)\n",
    "\n",
    "    # 4) 3CosMul（参考）: 頻度バイアスを抑えたい場合に試す\n",
    "    try:\n",
    "        results_mul = model.wv.most_similar_cosmul(\n",
    "            positive=positive, negative=negative, topn=10\n",
    "        )\n",
    "    except AttributeError:\n",
    "        results_mul = []\n",
    "\n",
    "    # 5) 結果表示（推定 Y は各手法のトップ）\n",
    "    print_results(\"3CosAdd (most_similar)\", results_add)\n",
    "    y_add = results_add[0][0]\n",
    "    print(f\"\\n推定 Y (Add): {y_add}\")\n",
    "\n",
    "    print_results(\"explicit vector → similar_by_vector\", results_vec)\n",
    "    y_vec = results_vec[0][0]\n",
    "    print(f\"\\n推定 Y (Vec): {y_vec}\")\n",
    "\n",
    "    if results_mul:\n",
    "        print_results(\"3CosMul (most_similar_cosmul)\", results_mul)\n",
    "        y_mul = results_mul[0][0]\n",
    "        print(f\"\\n推定 Y (Mul): {y_mul}\")\n",
    "\n",
    "    # 補足（実務上のヒント）:\n",
    "    # - 「夫」「主人」など複数候補が出る場合がある。目的に応じて人手ルールで正規化する。\n",
    "    # - ドメイン語彙の不足が原因なら，学習コーパス拡充・分かち書き統一・サブワード手法（FastText）を検討。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
