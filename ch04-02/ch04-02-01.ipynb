{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.2.1 NLU呼び出し用インスタンス生成（説明コメント付き・.envから資格情報読込版）\n",
    "# =============================================================================\n",
    "# 目的:\n",
    "#   ・IBM Watson Natural Language Understanding (NLU) の Python SDK を用いた\n",
    "#     クライアント(NaturalLanguageUnderstandingV1)の初期化を行う。\n",
    "#   ・APIキー/URL はハードコードせず、.env（またはOS環境変数）から安全に取得する。\n",
    "#\n",
    "# セキュリティ/運用の要点:\n",
    "#   ・ソースコード/リポジトリに認証情報をベタ書きしない（.env を .gitignore に追加する）。\n",
    "#   ・本番/開発で異なる資格情報を使い分ける場合、.env を切り替えるだけで済む構成にする。\n",
    "#   ・API バージョンは後方互換に注意。必要に応じて環境変数で上書き可能にしておく。\n",
    "#\n",
    "# 事前準備:\n",
    "#   1) python-dotenv を使用する場合はインストール:\n",
    "#        pip install python-dotenv\n",
    "#   2) プロジェクト直下に .env を作成（例）\n",
    "#        WATSON_NLU_APIKEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
    "#        WATSON_NLU_URL=https://api.jp-tok.natural-language-understanding.watson.cloud.ibm.com/instances/xxxxxxxx\n",
    "#        # （任意）バージョンを固定したい場合\n",
    "#        # WATSON_NLU_VERSION=2021-08-01\n",
    "#\n",
    "#   3) .gitignore に以下を追加して .env をコミットしない:\n",
    "#        .env\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# --- .env 読み込み（存在すれば） ------------------------------------------------\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    # override=False: 既にOS環境に同名キーがある場合は .env を優先しない（誤上書きを防ぐ）\n",
    "    load_dotenv(override=False)\n",
    "except ModuleNotFoundError:\n",
    "    # python-dotenv 未導入でも、OS環境変数から直接取得できるため致命的エラーにはしない\n",
    "    pass\n",
    "\n",
    "# --- 環境変数から資格情報を取得 -------------------------------------------------\n",
    "#   ・キー名の冗長化: 利用環境により命名が違っても拾えるようフォールバックを用意\n",
    "NLU_APIKEY = (\n",
    "    os.getenv(\"WATSON_NLU_APIKEY\")\n",
    "    or os.getenv(\"NLU_APIKEY\")\n",
    "    or os.getenv(\"IBM_WATSON_NLU_APIKEY\")\n",
    ")\n",
    "\n",
    "NLU_URL = (\n",
    "    os.getenv(\"WATSON_NLU_URL\")\n",
    "    or os.getenv(\"NLU_URL\")\n",
    "    or os.getenv(\"IBM_WATSON_NLU_URL\")\n",
    ")\n",
    "\n",
    "# 任意: バージョンは環境変数で上書き可能。指定が無ければ従来互換のデフォルトにする\n",
    "NLU_VERSION = os.getenv(\"WATSON_NLU_VERSION\", \"2019-07-12\")\n",
    "# ※ IBM の推奨最新版に合わせたい場合は適宜更新（例: \"2021-08-01\"）。SDK/サービス側の互換に注意。\n",
    "\n",
    "# --- バリデーション（早期失敗で原因を明確化） ---------------------------------\n",
    "missing = []\n",
    "if not NLU_APIKEY:\n",
    "    missing.append(\"WATSON_NLU_APIKEY\")\n",
    "if not NLU_URL:\n",
    "    missing.append(\"WATSON_NLU_URL\")\n",
    "\n",
    "if missing:\n",
    "    raise RuntimeError(\n",
    "        \"NLU の資格情報が不足しています。以下の環境変数を .env または OS 環境に設定してください: \"\n",
    "        + \", \".join(missing)\n",
    "    )\n",
    "\n",
    "# --- IBM Watson NLU SDK の初期化 ------------------------------------------------\n",
    "# SDKのimportは資格情報の検証後に行ってもよい（起動時エラーの責務分離）\n",
    "from ibm_watson import NaturalLanguageUnderstandingV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "# 旧スタイルのサブモジュール（v1のエクスポート）は必要に応じて:\n",
    "# from ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions, EntitiesOptions\n",
    "\n",
    "# 認証オブジェクト（IAM）\n",
    "authenticator = IAMAuthenticator(NLU_APIKEY)\n",
    "\n",
    "# クライアント生成:\n",
    "#  - version: API 呼び出しのバージョン日付。サービス仕様と整合する値を用いること。\n",
    "#  - authenticator: IAMAuthenticator を渡す。\n",
    "nlu = NaturalLanguageUnderstandingV1(version=NLU_VERSION, authenticator=authenticator)\n",
    "\n",
    "# サービスURLの設定（インスタンスごとに異なる）\n",
    "nlu.set_service_url(NLU_URL)\n",
    "\n",
    "# --- 動作確認の雛形（任意・コメントアウト） -----------------------------------\n",
    "# from ibm_watson.natural_language_understanding_v1 import Features, KeywordsOptions\n",
    "# try:\n",
    "#     resp = nlu.analyze(\n",
    "#         text=\"今日はいい天気ですね。Watsonでキーワード抽出を試します。\",\n",
    "#         features=Features(keywords=KeywordsOptions(limit=3))\n",
    "#     ).get_result()\n",
    "#     # print(resp)  # 返却JSON（実運用ではログに個人情報を出さないこと）\n",
    "# except Exception as e:\n",
    "#     # ネットワーク/認証/権限/リージョン誤りなどの例外をここで検知\n",
    "#     raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4675b7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.2.2 NLU呼び出し用共通関数（詳細コメント付き）\n",
    "# =============================================================================\n",
    "# 役割:\n",
    "#   - 事前に初期化済みの IBM Watson NLU クライアント（変数: nlu）を用いて\n",
    "#     テキスト解析 API を呼び出し、返却 JSON から関心のキーのみを取り出す。\n",
    "#\n",
    "# 使い方の要点（理論・API設計の観点）:\n",
    "#   - IBM Watson NLU では「どの分析を実行するか」を Features オブジェクトで宣言する\n",
    "#     （例: EntitiesOptions, KeywordsOptions, SentimentOptions, CategoriesOptions などを束ねる）。\n",
    "#   - `nlu.analyze(...)` は HTTP 経由で非同期実行され、`.get_result()` で Python dict(JSON) を返す。\n",
    "#   - 本関数はその dict から `key` で指定されたトップレベルの要素（例: \"entities\", \"keywords\"）を返す。\n",
    "#     * 存在しないキーを指定すると KeyError となる（後述の安全版で緩和可能）。\n",
    "#   - ネットワーク障害や認証失敗、レート制限などで例外が発生し得るため、呼び出し側で try/except を推奨。\n",
    "#\n",
    "# 例:\n",
    "#   from ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions\n",
    "#   feats = Features(entities=EntitiesOptions(limit=5, sentiment=False, emotion=False))\n",
    "#   entities = call_nlu(\"今日はいい天気ですね。\", feats, key=\"entities\")\n",
    "#   # entities は List[dict]（各エンティティのスパン、タイプ、スコア等を含む）\n",
    "#\n",
    "# 注意（実務）:\n",
    "#   - 入力テキストの長さ・言語・レート制限などサービス側の上限に留意（大きな文書は要分割）。\n",
    "#   - API のバージョンやリージョンにより挙動が異なる場合があるため、.env で設定を一元管理する。\n",
    "# =============================================================================\n",
    "\n",
    "from typing import Any, Dict, List, Union\n",
    "\n",
    "# Features 型は実行時には SDK から供給されるため、型ヒントとしての参照に留める\n",
    "# （循環 import を避けるためのフォワード参照も可能）\n",
    "try:\n",
    "    from ibm_watson.natural_language_understanding_v1 import (\n",
    "        Features,\n",
    "    )  # 型ヒント用（任意）\n",
    "except Exception:  # ランタイムに存在しない場合でも関数本体の実行には影響しない\n",
    "    Features = Any  # フォールバック（型チェックツール向けの便宜）\n",
    "\n",
    "\n",
    "def call_nlu(\n",
    "    text: str, features: \"Features\", key: str\n",
    ") -> Union[Dict[str, Any], List[Any], Any]:\n",
    "    \"\"\"\n",
    "    IBM Watson NLU を呼び出し、返却 JSON から指定キーの要素を取り出して返す薄いヘルパー。\n",
    "\n",
    "    引数:\n",
    "        text (str): 解析対象テキスト（UTF-8想定）\n",
    "        features (Features): 実行する分析機能の宣言（EntitiesOptions/KeywordsOptions 等を束ねたもの）\n",
    "        key (str): 返却 JSON のトップレベルキー（例: 'entities', 'keywords', 'sentiment', 'categories' など）\n",
    "\n",
    "    戻り値:\n",
    "        任意（Union[dict, list, Any]):\n",
    "            返却 JSON の `key` に対応する値（存在しないキーを指定すると KeyError）\n",
    "\n",
    "    例外:\n",
    "        - ネットワーク障害や認証エラー時に SDK 由来の例外が送出される。\n",
    "        - `key` が返却 JSON に無い場合は KeyError。\n",
    "\n",
    "    設計メモ:\n",
    "        - 本関数は「最小限の責務」に留めている（バリデーション/リトライ/ログは呼び出し側で制御）。\n",
    "        - 実運用では、レート制限や一時的なネットワーク失敗に備えたリトライ・指数バックオフ、\n",
    "          ならびに返却スキーマ検証（pydantic/dataclasses 等）を併用することを推奨。\n",
    "    \"\"\"\n",
    "    response = nlu.analyze(text=text, features=features).get_result()\n",
    "    return response[key]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# （任意）安全版: KeyError の回避・既定キー・軽いバリデーション・簡易リトライを追加する例\n",
    "# -----------------------------------------------------------------------------\n",
    "# from ibm_cloud_sdk_core.api_exception import ApiException\n",
    "# import time\n",
    "#\n",
    "# def call_nlu_safe(\n",
    "#     text: str,\n",
    "#     features: \"Features\",\n",
    "#     key: str | None = None,\n",
    "#     retries: int = 2,\n",
    "#     backoff_sec: float = 0.8,\n",
    "# ) -> Any:\n",
    "#     \"\"\"\n",
    "#     - KeyError を避け、key 未指定時は生の JSON を返す。\n",
    "#     - 一時的エラーに対して簡易リトライを行う。\n",
    "#     \"\"\"\n",
    "#     last_err = None\n",
    "#     for attempt in range(retries + 1):\n",
    "#         try:\n",
    "#             resp = nlu.analyze(text=text, features=features).get_result()\n",
    "#             if key is None:\n",
    "#                 return resp\n",
    "#             return resp.get(key, None)  # 無ければ None（呼び出し側で判定しやすい）\n",
    "#         except Exception as e:  # ApiException を個別に握るとより良い\n",
    "#             last_err = e\n",
    "#             if attempt < retries:\n",
    "#                 time.sleep(backoff_sec * (2 ** attempt))  # 指数バックオフ\n",
    "#                 continue\n",
    "#             raise last_err\n",
    "# -----------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ea7b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.2.3 エンティティ抽出機能の呼び出し（説明コメント付き）\n",
    "# =============================================================================\n",
    "# 目的:\n",
    "#   ・IBM Watson Natural Language Understanding (NLU) の「エンティティ抽出」を用いて、\n",
    "#     テキスト中から固有表現（人物・組織・地名・日付など）を検出し、JSON 形式で確認する。\n",
    "#\n",
    "# 背景/理論:\n",
    "#   ・エンティティ抽出 (Named Entity Recognition; NER) は、文中の名詞句をカテゴリ（PERSON, LOCATION 等）\n",
    "#     にラベル付けするタスク。以降の関係抽出・イベント抽出・検索インデキシングの基礎特徴となる。\n",
    "#   ・Watson NLU は言語自動判定を行うが、テキストが短い/混在言語のときは誤判定に注意。\n",
    "#     必要に応じて features に `language=\"ja\"` を付けるか、分析APIの別引数で明示指定する設計もあり。\n",
    "#\n",
    "# 事前準備:\n",
    "#   ・既に .env から資格情報を読み込み、`nlu` クライアントが初期化済み（リスト 4.2.1）。\n",
    "#   ・共通関数 `call_nlu(text, features, key)` が定義済み（リスト 4.2.2）。\n",
    "#\n",
    "# 出力:\n",
    "#   ・`entities` キー配下に、抽出されたエンティティの配列（各要素は text, type, relevance など）を返す。\n",
    "#   ・`ensure_ascii=False` で日本語を可読な形で表示。\n",
    "# =============================================================================\n",
    "\n",
    "# （補助）本セルだけで実行する場合に備えた import\n",
    "#  * 既にインポート済みなら重複定義は無害\n",
    "import json\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, EntitiesOptions\n",
    "\n",
    "# 対象テキスト\n",
    "# - 人物: 「安倍首相」「トランプ氏」\n",
    "# - 日付/時間: 「昨日」\n",
    "# - 施設/場所: 「大阪の国際会議場」\n",
    "# こうした固有表現が NER の検出対象になる。\n",
    "text = \"安倍首相はトランプ氏と昨日、大阪の国際会議場で会談した。\"\n",
    "\n",
    "# 機能として「エンティティ抽出機能」を利用\n",
    "# -----------------------------------------------------------------------------\n",
    "# EntitiesOptions の主なオプション例（必要に応じて拡張）:\n",
    "#   - limit: 返却件数上限\n",
    "#   - mentions: エンティティの各出現箇所（スパン）も含めるか\n",
    "#   - sentiment/emotion: エンティティごとの感情/極性分析を併せて実施\n",
    "#   - model: カスタム NLU モデルを指定（学習済みがある場合）\n",
    "# ここでは既定（全件・最小限情報）で実行する。\n",
    "features = Features(\n",
    "    entities=EntitiesOptions(\n",
    "        # limit=10,\n",
    "        # mentions=True,\n",
    "        # sentiment=False,\n",
    "        # emotion=False,\n",
    "        # model=\"<your-custom-model-id>\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# 共通関数呼び出し\n",
    "# - 第3引数 \"entities\" は NLU 返却 JSON のトップレベルキー。\n",
    "# - 例外（ネットワーク/認証/429 等）は呼び出し側で捕捉する設計（詳細はレビュー参照）。\n",
    "ret = call_nlu(text, features, \"entities\")\n",
    "\n",
    "# 結果の表示\n",
    "# - 抽出結果は配列（List[dict]）。各要素には \"type\", \"text\", \"relevance\", \"count\",\n",
    "#   場合によって \"disambiguation\"（同名異義の分解）などが含まれる。\n",
    "# - 日本語を読みやすくするため ensure_ascii=False。\n",
    "print(json.dumps(ret, indent=2, ensure_ascii=False))\n",
    "\n",
    "# =============================================================================\n",
    "# 注意/拡張ヒント:\n",
    "#   ・短文で誤検出が起きる場合は、前後文脈を足す/ドメイン固有語を事前正規化する/句点での分割を調整する。\n",
    "#   ・固有表現のカテゴリ粒度（例: \"人物肩書\" vs \"人名\"）はサービス側モデル依存。\n",
    "#   ・後続処理（例: ES へのインデックス、グラフDB でのノード登録）では、\n",
    "#     \"normalized_text\"（正規化表記）や \"disambiguation.dbpedia_resource\" 等の正規IDをキーに採用すると安定。\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.2.4 関係抽出機能の呼び出し（説明コメント付き）\n",
    "# =============================================================================\n",
    "# 目的:\n",
    "#   ・IBM Watson Natural Language Understanding (NLU) の「関係抽出（Relation Extraction）」機能を用いて、\n",
    "#     文中のエンティティ間の関係（主語-述語-目的語 等の関係ラベル/役割）を検出し、JSON で確認する。\n",
    "#\n",
    "# 背景/理論:\n",
    "#   ・関係抽出は、まず NER（固有表現抽出）で候補エンティティを同定 → そのペア（または n-項）の\n",
    "#     間に成り立つ意味関係をラベリングするタスクである。\n",
    "#   ・一般的には (subject, relation, object) の三つ組や、argument 役割（ARG0/ARG1 等）として返る。\n",
    "#   ・Watson NLU では `relations` を有効化すると、内部でエンティティ・句構造を解析し、\n",
    "#     「開催地」「所属」「位置」などの関係を推定する（具体的ラベルはモデル依存）。\n",
    "#\n",
    "# 実務上の要点:\n",
    "#   ・短文や文脈の乏しい文では関係の自信度が低くなりやすい。必要なら文脈を付与して精度を上げる。\n",
    "#   ・日本語判定が揺れると解析器の選択が変わり結果が不安定になるため、必要に応じて language=\"ja\" を\n",
    "#     明示指定する（本スニペットは共通関数 call_nlu をそのまま使うため引数追加はしていない）。\n",
    "#   ・返却 JSON はモデル/バージョンで微細に変化し得るため、下流でのキー存在チェックを推奨。\n",
    "#\n",
    "# オプション設計のヒント:\n",
    "#   ・RelationsOptions には（環境により）`model` などの指定が可能（独自学習モデルがある場合に利用）。\n",
    "#   ・関係抽出は NER の質に依存するため、同時に EntitiesOptions(mentions=True) で可視化すると\n",
    "#     デバッグしやすい（どのスパンが関係の対象になったか追跡できる）。\n",
    "#\n",
    "# 依存:\n",
    "#   ・前段で NLU クライアント `nlu` が初期化済み（.env から資格情報読込）であること（リスト 4.2.1）。\n",
    "#   ・共通関数 `call_nlu(text, features, key)` が定義済みであること（リスト 4.2.2）。\n",
    "# =============================================================================\n",
    "\n",
    "# 最小限の import（このセル単体での実行にも耐えるようにしておく）\n",
    "import json\n",
    "from ibm_watson.natural_language_understanding_v1 import Features, RelationsOptions\n",
    "\n",
    "# ※ call_nlu は前段で定義済みの想定。未定義なら call_nlu_safe を用意するか、nlu.analyze を直接呼ぶ。\n",
    "\n",
    "# 対象テキスト\n",
    "# - エンティティ候補: 「このイベント」（抽象イベント）、「東京」（地名）、「国立競技場」（施設）\n",
    "# - 期待される関係例: \"開催地(location_of_event)\" や \"場所(at)\" に相当する関係ラベル（モデル依存）\n",
    "text = \"このイベントは東京の国立競技場で開催されました。\"\n",
    "\n",
    "# 機能として「関係抽出機能」を利用\n",
    "# -----------------------------------------------------------------------------\n",
    "# RelationsOptions の主な指定例（必要に応じて利用）:\n",
    "#   - model=\"<custom-model-id>\"   : カスタム学習済み関係抽出モデルがある場合に指定\n",
    "#   - language=\"ja\"               : analyze 引数に渡すのが一般的（call_nlu を拡張するか、直接呼び出す）\n",
    "# ここでは既定の関係抽出を用いる。\n",
    "features = Features(\n",
    "    relations=RelationsOptions(\n",
    "        # model=\"<your-custom-relations-model-id>\"  # 例: カスタムモデルがある場合\n",
    "    )\n",
    ")\n",
    "\n",
    "# 共通関数呼び出し\n",
    "# - \"relations\" キー配下に、検出された関係の配列が返る。\n",
    "# - 各要素は \"type\"（関係ラベル）、\"arguments\"（関係を構成するエンティティ/スパンと役割）、\n",
    "#   \"sentence\"（対象文）などを含むことが多い（モデル/バージョンに依存）。\n",
    "ret = call_nlu(text, features, \"relations\")\n",
    "\n",
    "# 結果の表示\n",
    "# - ensure_ascii=False: 日本語を可読表示。\n",
    "# - 返却例イメージ（参考/実行環境で変動）:\n",
    "#   [\n",
    "#     {\n",
    "#       \"type\": \"located_at\",\n",
    "#       \"sentence\": \"このイベントは東京の国立競技場で開催されました。\",\n",
    "#       \"arguments\": [\n",
    "#         {\"text\": \"このイベント\", \"entities\": [...], \"location\": {...}, \"role\": \"subject\"},\n",
    "#         {\"text\": \"国立競技場\",   \"entities\": [...], \"location\": {...}, \"role\": \"object\"}\n",
    "#       ]\n",
    "#     }\n",
    "#   ]\n",
    "print(json.dumps(ret, indent=2, ensure_ascii=False))\n",
    "\n",
    "# =============================================================================\n",
    "# 注意/拡張:\n",
    "#   ・誤検出/過検出が見られる場合:\n",
    "#       - 文を短く分割しすぎない（係り受け情報が失われる）\n",
    "#       - 補足文脈を足す（主語省略の補完）\n",
    "#       - NER の mentions を併用してスパンを確認（関係の引数抽出が適切か検証）\n",
    "#   ・スキーマの安定運用:\n",
    "#       - 下流では \"type\" と \"arguments[*].role/text\" を必須キーとして扱い、欠落時はスキップ/要再解析。\n",
    "#       - ログには原文を残さず、必要最小限のメタ情報（関係タイプ、引数の正規表記）を記録。\n",
    "#   ・評価:\n",
    "#       - 開発コーパスで関係タイプごとの適合率/再現率/F1 を算出し、文体差（ニュース/ブログ/広報）に対する頑健性を確認。\n",
    "# ============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb17b281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
