{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34a9ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = [\n",
    "    \"泉質\",\n",
    "    \"温泉\",\n",
    "    \"温泉法\",\n",
    "    \"温泉分析書\",\n",
    "    \"万座温泉\",\n",
    "    \"伊東温泉\",\n",
    "    \"吉野温泉\",\n",
    "    \"塩江温泉\",\n",
    "    \"塩津温泉\",\n",
    "    \"大子温泉\",\n",
    "    # '山田温泉',  # 山田温泉はユニークに決まらないのでとりあえずはずしてあります。\n",
    "    # 詳細は 2.1節を読んで下さい。\n",
    "    \"川棚温泉\",\n",
    "    \"指宿温泉\",\n",
    "    \"玉造温泉\",\n",
    "    \"登別温泉\",\n",
    "    \"花山温泉\",\n",
    "    \"雲仙温泉\",\n",
    "    \"鳴子温泉\",\n",
    "    \"鳴子温泉郷\",\n",
    "    \"大歩危温泉\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c3d508",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "import wikipedia\n",
    "\n",
    "wikipedia.set_lang(\"ja\")\n",
    "# wikipediaの記事の読み取り\n",
    "\n",
    "for index, title in enumerate(title_list):\n",
    "    print(index + 1, title)\n",
    "    text = wikipedia.page(title, auto_suggest=False).content\n",
    "    item = {\"app_id\": index + 1, \"title\": title, \"text\": text}\n",
    "    data_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d7ca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資格情報の設定 (個別に設定します)\n",
    "\n",
    "discovery_credentials = {\n",
    "    \"apikey\": \"xxxx\",\n",
    "    \"iam_apikey_description\": \"xxxx\",\n",
    "    \"iam_apikey_name\": \"xxxx\",\n",
    "    \"iam_role_crn\": \"xxxx\",\n",
    "    \"iam_serviceid_crn\": \"xxxx\",\n",
    "    \"url\": \"xxxx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e633926c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovery APIの初期化\n",
    "\n",
    "import json\n",
    "import os\n",
    "from ibm_watson import DiscoveryV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "version = \"2019-04-30\"\n",
    "\n",
    "authenticator = IAMAuthenticator(discovery_credentials[\"apikey\"])\n",
    "discovery = DiscoveryV1(version=version, authenticator=authenticator)\n",
    "discovery.set_service_url(discovery_credentials[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87e33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment_id、collection_id、configuration_id の取得\n",
    "# すでにUIで1つのprivate collectionが作成済みであることが前提\n",
    "\n",
    "# environment id の取得\n",
    "environment_id = discovery.list_environments().get_result()[\"environments\"][1][\n",
    "    \"environment_id\"\n",
    "]\n",
    "print(\"environment_id: \", environment_id)\n",
    "\n",
    "# collection id の取得\n",
    "collection_id = discovery.list_collections(environment_id).get_result()[\"collections\"][\n",
    "    0\n",
    "][\"collection_id\"]\n",
    "print(\"collection_id: \", collection_id)\n",
    "\n",
    "# configuration_idの取得\n",
    "configuration_id = discovery.list_configurations(environment_id).get_result()[\n",
    "    \"configurations\"\n",
    "][0][\"configuration_id\"]\n",
    "print(\"configuration_id: \", configuration_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d016d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書ロード関数\n",
    "# collection_id: 対象コレクション\n",
    "# sample_data: 書き込み対象テキスト (json形式の配列)\n",
    "# key_name: 文書のユニークキー名称\n",
    "\n",
    "\n",
    "def load_text(collection_id, sample_data, key_name):\n",
    "    for item in sample_data:\n",
    "\n",
    "        # itemごとにワークのjsonファイルを作成\n",
    "        print(item)\n",
    "        key = item.get(key_name)\n",
    "        filename = str(key) + \".json\"\n",
    "        f = open(filename, \"w\")\n",
    "        json.dump(item, f)\n",
    "        f.close()\n",
    "\n",
    "        # 書き込み可能かのチェック\n",
    "        collection = discovery.get_collection(\n",
    "            environment_id, collection_id\n",
    "        ).get_result()\n",
    "        proc_docs = collection[\"document_counts\"][\"processing\"]\n",
    "        while True:\n",
    "            if proc_docs < 20:\n",
    "                break\n",
    "            print(\"busy. waiting..\")\n",
    "            time.sleep(10)\n",
    "            collection = discovery.get_collection(environment_id, collection_id)\n",
    "            proc_docs = collection[\"document_counts\"][\"processing\"]\n",
    "\n",
    "        # jsonファイル名を引数にDiscoveryへデータロード\n",
    "        with open(filename) as f:\n",
    "            add_doc = discovery.add_document(environment_id, collection_id, file=f)\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8039421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定のコレクションの全文書を削除する関数\n",
    "# collection_id: 対象コレクション\n",
    "\n",
    "\n",
    "def delete_all_docs(collection_id):\n",
    "\n",
    "    # 文書件数取得\n",
    "    collection = discovery.get_collection(environment_id, collection_id).get_result()\n",
    "    doc_count = collection[\"document_counts\"][\"available\"]\n",
    "\n",
    "    results = discovery.query(\n",
    "        environment_id, collection_id, return_fields=\"id\", count=doc_count\n",
    "    ).get_result()[\"results\"]\n",
    "    ids = [item[\"id\"] for item in results]\n",
    "\n",
    "    for id in ids:\n",
    "        print(\"deleting doc: id =\" + id)\n",
    "        discovery.delete_document(environment_id, collection_id, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0493debc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 既存文書の全削除\n",
    "delete_all_docs(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691905af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia文書のロード\n",
    "load_text(collection_id, data_list, \"app_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480d068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト4.8.1\n",
    "\n",
    "# トレーニングデータの全削除\n",
    "discovery.delete_all_training_data(environment_id, collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6564d1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト4.8.2 ー Discovery の自然言語問い合わせ（Natural Language Query）\n",
    "# -----------------------------------------------------------------------------\n",
    "# 本スニペットは IBM Watson Discovery（V1）に対して、日本語の自然文をそのまま\n",
    "# 検索クエリとして渡す例である。キーワード検索（query=...）と異なり、\n",
    "# natural_language_query は内部でクエリ解釈（意図推定・語の正規化・重要語抽出等）\n",
    "# を行い、より人間の質問文に近い形で関連文書をランキングする。\n",
    "#\n",
    "# 【前提】\n",
    "# - `discovery` は既に認証・初期化済み（4.6 節のコード参照）。\n",
    "# - `environment_id`, `collection_id` は既に取得済み（4.6.2 参照）。\n",
    "# - 形態素辞書や Knowledge Studio モデルを登録している場合、\n",
    "#   トークン化・エンティティ正規化の結果がランキングに影響する。\n",
    "#\n",
    "# 【理論メモ（IR 観点）】\n",
    "# - natural_language_query は BM25 / tf-idf 系統の語彙統計と\n",
    "#   ML ランカー（実装詳細は非公開）を組み合わせ、語の重要度（idf）や文書長正規化、\n",
    "#   フィールド構造等を加味してスコアリングするのが一般的な理解である。\n",
    "# - 日本語ではトークナイザ（分かち書き）と同義語展開の設計がスコアに直結する。\n",
    "#   同義語は再現率を上げる一方で idf を下げコントラストを弱める可能性がある。\n",
    "#\n",
    "# 【実務 Tips】\n",
    "# - 返却項目は `return_fields` で最小限に絞ると I/O とメモリを節約できる。\n",
    "# - 取得件数は `count=` で明示指定可能（既定は環境依存）。\n",
    "# - 空結果や例外（429/5xx）は運用上リトライ/バックオフで扱うこと。\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "# 自然言語問い合わせ（質問文そのものを入力）\n",
    "# 例: 「温泉の特徴や泉質などの分類」という意図を自然文で渡す。\n",
    "query_text = \"温泉の特徴や泉質などの分類\"\n",
    "\n",
    "# 検索結果で返してほしいフィールドを列挙（最小限にするのが基本）\n",
    "# ここではアプリ内での識別子 app_id とタイトルのみを要求\n",
    "return_fields = \"app_id,title\"\n",
    "\n",
    "# Discovery への問い合わせを実行。\n",
    "# - natural_language_query: 自然文（質問文）を渡す入口\n",
    "# - return_fields: 出力項目の絞り込み\n",
    "# - get_result(): SDK のレスポンスオブジェクトから素の dict を取得\n",
    "# 補足:\n",
    "#   - 取得件数を制御する場合は count=10 等を追加する。\n",
    "#   - 類義語辞書やエンリッチ設定を更新した直後はインデクシング完了を待つこと。\n",
    "query_results = discovery.query(\n",
    "    environment_id,\n",
    "    collection_id,\n",
    "    natural_language_query=query_text,\n",
    "    return_fields=return_fields,\n",
    ").get_result()\n",
    "\n",
    "# 実際のヒット配列は \"results\" キーに格納される。\n",
    "# 各要素には result_metadata.score（関連度スコア）等が含まれる点も活用可能。\n",
    "# 例外/空配列の取り扱いは呼び出し側で実装するのが望ましい。\n",
    "res2 = query_results[\"results\"]\n",
    "\n",
    "# （任意のデバッグ例：必要に応じてコメント解除）\n",
    "# import json\n",
    "# print(json.dumps(res2, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bab47c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト4.8.3\n",
    "# -----------------------------------------------------------------------------\n",
    "# 問い合わせ結果（res2）を人が確認しやすい形で出力しつつ、\n",
    "# Discovery の学習データ（relevance training）で用いる examples 配列を組み立てる。\n",
    "#\n",
    "# 【前提】\n",
    "# - 直前のリスト4.8.2で実行した自然言語問い合わせの結果 dict から、\n",
    "#   res2 = query_results['results'] が定義済みであること。\n",
    "# - Discovery V1 の学習 API（add_training_data 等）では\n",
    "#   examples の各要素に {document_id, cross_reference, relevance} を渡す。\n",
    "#   - document_id: Discovery が付与した一意のドキュメント ID（item['id']）\n",
    "#   - cross_reference: 任意の外部参照（ここではコーパス側で付けた app_id を使う）\n",
    "#   - relevance: 人手ラベル（0/1/2 など）。ここでは 0（未ラベル）で初期化し、後で人手で上書きする想定。\n",
    "#\n",
    "# 【実装メモ】\n",
    "# - result_metadata.score はランキング（BM25 等の語彙統計＋学習ランカー）に基づく関連度スコア。\n",
    "# - result_metadata.confidence は設定やエンリッチ結果によっては付与されないことがあるため get で読む。\n",
    "# - 例外や欠損に強くするため dict.get を利用している。\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "examples = []  # 学習用 example の入れ物\n",
    "\n",
    "# res2: discovery.query(...).get_result()['results'] を想定\n",
    "for item in res2:\n",
    "    # Discovery が返す内部 ID（トレーニング API で document_id に渡す）\n",
    "    document_id = item.get(\"id\")\n",
    "\n",
    "    # ランキングに関するメタデータ。score は基本的に常に返るが、confidence は無い場合がある\n",
    "    metadata = item.get(\"result_metadata\", {})\n",
    "    score = metadata.get(\"score\")  # 関連度スコア（大きいほど関連する）\n",
    "    confidence = metadata.get(\"confidence\")  # 存在しないケースがあるため None 許容\n",
    "\n",
    "    # インデックス時に入れておいたメタ情報（4.6 系で投入済みの app_id/title）\n",
    "    app_id = item.get(\"app_id\")  # 学習時の cross_reference に流用\n",
    "    title = item.get(\"title\")  # デバッグ出力用\n",
    "\n",
    "    # 学習データの 1 件分（relevance は後で人手で 1/2 などに上げる想定）\n",
    "    example = {\n",
    "        \"document_id\": document_id,  # Discovery のドキュメント ID\n",
    "        \"cross_reference\": app_id,  # 人間に見せる参照用 ID（自前の ID）\n",
    "        \"relevance\": 0,  # 初期ラベル（未ラベル=0）。良ければ 2、やや関連なら 1 などへ更新\n",
    "    }\n",
    "\n",
    "    # 確認用に一行で主要情報を表示（スコアで並べ替えたい場合は、事前に res2 を sort する）\n",
    "    print(document_id, title, app_id, score, confidence)\n",
    "\n",
    "    # 例の配列に追加\n",
    "    examples.append(example)\n",
    "\n",
    "# （任意）後工程のため examples を確認したい場合：\n",
    "# import json; print(json.dumps(examples, indent=2, ensure_ascii=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a71275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト4.8.4\n",
    "\n",
    "# examples配列の完成\n",
    "examples[0][\"relevance\"] = 10\n",
    "examples[1][\"relevance\"] = 10\n",
    "\n",
    "for example in examples:\n",
    "    print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa99d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.8.5\n",
    "# -----------------------------------------------------------------------------\n",
    "# ランキング学習（Discovery のトレーニングデータ登録）を実施する。\n",
    "#\n",
    "# 【前提（これまでの手順との対応）】\n",
    "# - environment_id, collection_id …… 4.6.x 系で取得済みの有効な ID。\n",
    "# - query_text …… 4.8.2 の自然言語問い合わせで用いたクエリ文字列（例：「温泉の特徴や泉質などの分類」）。\n",
    "# - examples …… 4.8.3 で組み立てた配列。\n",
    "#     例: [{'document_id': <Discoveryのdoc id>, 'cross_reference': <自前のapp_id等>, 'relevance': 0/1/2}, ...]\n",
    "#\n",
    "# 【この API 呼び出しの意味】\n",
    "# - natural_language_query（自然文クエリ）に対して、関連度ラベル付きの文書例（examples）を登録する。\n",
    "# - 登録された「クエリ＋例」のセットが学習データとなり、以後のランキング最適化に反映される。\n",
    "#   ※ 反映は非同期（バックグラウンド学習）で行われ、反映まで時間がかかることがある。\n",
    "#\n",
    "# 【運用・注意点】\n",
    "# - examples の document_id は Discovery が返す検索結果 item['id']（コレクション内でユニーク）を必ず使用する。\n",
    "# - relevance の意味づけ（一般例）:\n",
    "#     2: 強い正例（非常に関連） / 1: 正例（関連） / 0: 未ラベルまたは非関連\n",
    "#   最初は 0 で登録し、人手確認後に 1/2 へ更新する運用でもよい。\n",
    "# - 同一の natural_language_query に対して何度も add_training_data を実行すると重複/上書きが起こり得る。\n",
    "#   必要に応じて list_training_data / delete_training_data 等で管理・クリーンアップする。\n",
    "# - 429（Rate limit）や 403（権限）エラー時はレート制御や資格情報を再確認する。\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "train_results = discovery.add_training_data(\n",
    "    environment_id,\n",
    "    collection_id,\n",
    "    natural_language_query=query_text,  # 学習対象の自然文クエリ\n",
    "    examples=examples,  # 当該クエリに対する文書のラベル集合\n",
    ").get_result()\n",
    "\n",
    "# （任意）レスポンスの中身を確認して監査ログに残すと良い：\n",
    "# - 'query_id': 学習クエリの ID\n",
    "# - 'updated' : 更新時刻\n",
    "# - 'examples': 受理された examples の要約\n",
    "# 例：\n",
    "# import json\n",
    "# print(json.dumps(train_results, ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c2a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.8.6\n",
    "\n",
    "# ランキング学習結果の確認\n",
    "res2 = train_results[\"examples\"]\n",
    "for item in res2:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
