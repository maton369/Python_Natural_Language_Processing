{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed9e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 日本百名湯のうち、wikipediaに記事のある温泉のリスト\n",
    "# -----------------------------------------------------------------------------\n",
    "# 目的:\n",
    "#   ・後続の NLP / 検索（例: TF-IDF, Elasticsearch, Discovery）に用いる学習/評価コーパスとして、\n",
    "#     Wikipedia（日本語）から「日本百名湯」に関する本文テキストを収集する。\n",
    "# 背景・理論的補足:\n",
    "#   ・Wikipedia は汎用百科事典ゆえ、用語説明や歴史・地理・泉質など多様な語彙が混在する。\n",
    "#     これはベクトル化（BoW/TF-IDF/word2vec/BERT 等）や同義語展開の効果検証に向く。\n",
    "#   ・語彙分布は Zipf 則に従いやすく、上位語の出現頻度が高くなるため、ベクトル化時は\n",
    "#     stopword/品詞フィルタや max_df/min_df 等の抑制が理にかなう。\n",
    "#   ・Wikipedia 由来のデータは CC BY-SA / GFDL のライセンスに従う必要がある。派生物利用時は注意。\n",
    "# 運用上の注意:\n",
    "#   ・`wikipedia` パッケージは内部で MediaWiki API を叩く。回数/速度が多い場合はレート制御を検討。\n",
    "#   ・auto_suggest=False により題名の曖昧補正を無効化しているため、存在しない/曖昧な項目では\n",
    "#     例外（DisambiguationError/PageError）が発生する。実運用では try/except で握るのが望ましい。\n",
    "#   ・本文は wiki マークアップを含むプレーンテキスト（セクション見出し \"== ==\" など）で返る。\n",
    "#     後段の形態素解析では不要記号の除去等の前処理が有効（例: 正規化・記号除去）。\n",
    "title_list = [\n",
    "    \"菅野温泉\",\n",
    "    \"養老牛温泉\",\n",
    "    \"定山渓温泉\",\n",
    "    \"登別温泉\",\n",
    "    \"洞爺湖温泉\",\n",
    "    \"ニセコ温泉郷\",\n",
    "    \"朝日温泉 (北海道)\",\n",
    "    \"酸ヶ湯温泉\",\n",
    "    \"蔦温泉\",\n",
    "    \"花巻南温泉峡\",\n",
    "    \"夏油温泉\",\n",
    "    \"須川高原温泉\",\n",
    "    \"鳴子温泉郷\",\n",
    "    \"遠刈田温泉\",\n",
    "    \"峩々温泉\",\n",
    "    \"乳頭温泉郷\",\n",
    "    \"後生掛温泉\",\n",
    "    \"玉川温泉 (秋田県)\",\n",
    "    \"秋ノ宮温泉郷\",\n",
    "    \"銀山温泉\",\n",
    "    \"瀬見温泉\",\n",
    "    \"赤倉温泉 (山形県)\",\n",
    "    \"東山温泉\",\n",
    "    \"飯坂温泉\",\n",
    "    \"二岐温泉\",\n",
    "    \"那須温泉郷\",\n",
    "    \"塩原温泉郷\",\n",
    "    \"鬼怒川温泉\",\n",
    "    \"奥鬼怒温泉郷\",\n",
    "    \"草津温泉\",\n",
    "    \"伊香保温泉\",\n",
    "    \"四万温泉\",\n",
    "    \"法師温泉\",\n",
    "    \"箱根温泉\",\n",
    "    \"湯河原温泉\",\n",
    "    \"越後湯沢温泉\",\n",
    "    \"松之山温泉\",\n",
    "    \"大牧温泉\",\n",
    "    \"山中温泉\",\n",
    "    \"山代温泉\",\n",
    "    \"粟津温泉\",\n",
    "    \"奈良田温泉\",\n",
    "    \"西山温泉 (山梨県)\",\n",
    "    \"野沢温泉\",\n",
    "    \"湯田中温泉\",\n",
    "    \"別所温泉\",\n",
    "    \"中房温泉\",\n",
    "    \"白骨温泉\",\n",
    "    \"小谷温泉\",\n",
    "    \"下呂温泉\",\n",
    "    \"福地温泉\",\n",
    "    \"熱海温泉\",\n",
    "    \"伊東温泉\",\n",
    "    \"修善寺温泉\",\n",
    "    \"湯谷温泉 (愛知県)\",\n",
    "    \"榊原温泉\",\n",
    "    \"木津温泉\",\n",
    "    \"有馬温泉\",\n",
    "    \"城崎温泉\",\n",
    "    \"湯村温泉 (兵庫県)\",\n",
    "    \"十津川温泉\",\n",
    "    \"南紀白浜温泉\",\n",
    "    \"南紀勝浦温泉\",\n",
    "    \"湯の峰温泉\",\n",
    "    \"龍神温泉\",\n",
    "    \"奥津温泉\",\n",
    "    \"湯原温泉\",\n",
    "    \"三朝温泉\",\n",
    "    \"岩井温泉\",\n",
    "    \"関金温泉\",\n",
    "    \"玉造温泉\",\n",
    "    \"有福温泉\",\n",
    "    \"温泉津温泉\",\n",
    "    \"湯田温泉\",\n",
    "    \"長門湯本温泉\",\n",
    "    \"祖谷温泉\",\n",
    "    \"道後温泉\",\n",
    "    \"二日市温泉 (筑紫野市)\",\n",
    "    \"嬉野温泉\",\n",
    "    \"武雄温泉\",\n",
    "    \"雲仙温泉\",\n",
    "    \"小浜温泉\",\n",
    "    \"黒川温泉\",\n",
    "    \"地獄温泉\",\n",
    "    \"垂玉温泉\",\n",
    "    \"杖立温泉\",\n",
    "    \"日奈久温泉\",\n",
    "    \"鉄輪温泉\",\n",
    "    \"明礬温泉\",\n",
    "    \"由布院温泉\",\n",
    "    \"川底温泉\",\n",
    "    \"長湯温泉\",\n",
    "    \"京町温泉\",\n",
    "    \"指宿温泉\",\n",
    "    \"霧島温泉郷\",\n",
    "    \"新川渓谷温泉郷\",\n",
    "    \"栗野岳温泉\",\n",
    "]\n",
    "\n",
    "# wikipediaの記事の読み取り\n",
    "# -----------------------------------------------------------------------------\n",
    "# 役割:\n",
    "#   ・`wikipedia` ライブラリで各タイトルの記事本文を取得し、後続処理で扱いやすい dict に整形。\n",
    "# 実装ポイント:\n",
    "#   ・`set_lang(\"ja\")` により日本語版 API を利用。ローカライズされた語彙・表記を得られる。\n",
    "#   ・進捗可視化のために (index+1, title) を逐次 print。\n",
    "#   ・`app_id` は 1 始まりの連番。外部システム（Elasticsearch/Discovery）に投入する際の\n",
    "#     ドキュメント ID として再利用しやすい設計。\n",
    "# 例外対策（コメントのみ）:\n",
    "#   ・曖昧さ回避ページ（Disambiguation）や記事未存在（PageError）に備え、\n",
    "#     本番は try/except でスキップ/リトライ/タイトル調整を行うのがよい。\n",
    "import wikipedia\n",
    "\n",
    "wikipedia.set_lang(\"ja\")\n",
    "\n",
    "data_list = (\n",
    "    []\n",
    ")  # 収集結果の蓄積先（リスト of 辞書）。後段のインデクシングでそのまま回せる形。\n",
    "for index, title in enumerate(title_list):\n",
    "    print(index + 1, title)  # 収集進捗のログ出力（長尺バッチ時の可観測性向上）\n",
    "    # `auto_suggest=False`:\n",
    "    #   ・類似タイトルへの自動補正を抑止し、意図しない別記事の取得を回避。\n",
    "    #   ・ただしタイトルの微妙な揺れを拾えないため、失敗時は例外となる点に注意。\n",
    "    text = wikipedia.page(title, auto_suggest=False).content\n",
    "    # データ構造:\n",
    "    #   ・app_id: 外部システムの主キーに合わせるための 1-based 連番\n",
    "    #   ・title : 記事タイトル（照合/可読性のため保持）\n",
    "    #   ・text  : 記事本文（wiki マークアップ除去は未実施。前処理段で正規化/品詞抽出などを行う）\n",
    "    item = {\"app_id\": index + 1, \"title\": title, \"text\": text}\n",
    "    data_list.append(\n",
    "        item\n",
    "    )  # ダウンストリーム（TF-IDF/同義語検証/類似検索評価）へ受け渡す基礎データとして格納\n",
    "\n",
    "# 提示データの想定利用:\n",
    "#   ・形態素解析（MeCab/Janome/kuromoji）→ トークン化・原形化・品詞フィルタ\n",
    "#   ・ベクトル化（TF-IDF, BM25, sentence-transformers など）→ 特徴語抽出/類似度計算\n",
    "#   ・検索基盤（Elasticsearch/Watson Discovery）→ 日本語アナライザ/同義語辞書/ユーザー辞書の効果検証\n",
    "# 品質検証の観点:\n",
    "#   ・「泉質語彙」「地名」「観光/歴史表現」の混在がコーパスの多様性を高め、検索の recall/precision の\n",
    "#     トレードオフ評価や、辞書・同義語ルールの当たり/外れの見極めに適している。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ca215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 資格情報の設定 (個別に設定します)\n",
    "\n",
    "discovery_credentials = {\n",
    "    \"apikey\": \"xxxx\",\n",
    "    \"iam_apikey_description\": \"xxxx\",\n",
    "    \"iam_apikey_name\": \"xxxx\",\n",
    "    \"iam_role_crn\": \"xxxx\",\n",
    "    \"iam_serviceid_crn\": \"xxxx\",\n",
    "    \"url\": \"xxxx\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88578131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discovery APIの初期化\n",
    "\n",
    "import json\n",
    "import os\n",
    "from ibm_watson import DiscoveryV1\n",
    "from ibm_cloud_sdk_core.authenticators import IAMAuthenticator\n",
    "\n",
    "version = \"2019-04-30\"\n",
    "\n",
    "authenticator = IAMAuthenticator(discovery_credentials[\"apikey\"])\n",
    "discovery = DiscoveryV1(version=version, authenticator=authenticator)\n",
    "discovery.set_service_url(discovery_credentials[\"url\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aaca3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment_id、collection_id、configuration_id の取得\n",
    "# すでにUIで1つのprivate collectionが作成済みであることが前提\n",
    "\n",
    "# environment id の取得\n",
    "environments = discovery.list_environments().get_result()[\"environments\"]\n",
    "environment_id = environments[0][\"environment_id\"]\n",
    "if environment_id == \"system\":\n",
    "    environment_id = environments[1][\"environment_id\"]\n",
    "print(\"environment_id: \", environment_id)\n",
    "\n",
    "# collection id の取得\n",
    "collection_id = discovery.list_collections(environment_id).get_result()[\"collections\"][\n",
    "    0\n",
    "][\"collection_id\"]\n",
    "print(\"collection_id: \", collection_id)\n",
    "\n",
    "# configuration idの取得\n",
    "configuration_id = discovery.list_configurations(environment_id).get_result()[\n",
    "    \"configurations\"\n",
    "][0][\"configuration_id\"]\n",
    "print(\"configuration_id: \", configuration_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c2b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 文書ロード関数\n",
    "# collection_id: 対象コレクション\n",
    "# sample_data: 書き込み対象テキスト (json形式の配列)\n",
    "# key_name: 文書のユニークキー名称\n",
    "#\n",
    "# 前提条件（この関数の外側で準備が必要）:\n",
    "#   - Discovery クライアント `discovery` が初期化済みであること\n",
    "#   - ターゲット環境ID `environment_id` が取得済みであること\n",
    "#   - 次の標準ライブラリが import 済みであること: json, os, time\n",
    "#       例)\n",
    "#         import json\n",
    "#         import os\n",
    "#         import time\n",
    "#\n",
    "# 設計・理論的な意図:\n",
    "#   - IBM Watson Discovery のコレクションへ大量ドキュメントを一括投入する際に\n",
    "#     短時間で処理キュー（processing キュー）を過負荷にしないことが重要。\n",
    "#     本関数はコレクションの `document_counts.processing` を監視し、\n",
    "#     閾値（ここでは 20）未満になるまで待機することでスロットリング（バックオフ）を実装している。\n",
    "#     これは外部APIへの負荷制御（rate limiting/backpressure）の一種。\n",
    "#   - JSON を一時ファイルとして書き出し → `add_document` にファイルオブジェクトを渡す構成。\n",
    "#     Discovery はファイルアップロード型の API を提供するため、この経路が簡便。\n",
    "#   - 各ドキュメントのユニークキー（`key_name`）をファイル名に用いることで、\n",
    "#     ログ/監査/リトライのトレース性を確保。\n",
    "#   - 実運用では:\n",
    "#       * 日本語を可読のまま保存したい場合は `json.dump(..., ensure_ascii=False)` を推奨。\n",
    "#       * 例外（ネットワーク障害/スロット満杯/権限エラーなど）を try/except で握り、リトライ/スキップを行う。\n",
    "#       * `tempfile` モジュールで衝突しない一時ファイルを作ると安全（並列時の競合回避）。\n",
    "#       * 閾値 20 は環境・プランに依存するため、経験則に応じて調整。\n",
    "#\n",
    "# 実装上の注意:\n",
    "#   - `discovery.get_collection(...).get_result()` の戻り値は dict。\n",
    "#     while ループ内の再取得時にも `.get_result()` を付け忘れると、DetailedResponse のままで\n",
    "#     `[...]` による辞書アクセスが失敗するため注意（※下の該当行に注意喚起コメントを付与）。\n",
    "#   - `open(..., 'w')` は明示的に `encoding='utf-8'` を与えるのが安全（環境依存の文字化け回避）。\n",
    "#   - `json.dump` の既定は ASCII エスケープ。日本語をそのまま残すなら `ensure_ascii=False` を検討。\n",
    "def load_text(collection_id, sample_data, key_name):\n",
    "    for item in sample_data:\n",
    "        # 1) アップロード対象ドキュメントの可視化（ログ出力）\n",
    "        #    - デバッグ/監査のために item 全体を表示（サイズが大きい場合は要約推奨）。\n",
    "        print(item)\n",
    "\n",
    "        # 2) 一時 JSON ファイルの作成\n",
    "        #    - ユニークキーをファイル名に採用し、投入対象を特定しやすくする。\n",
    "        #    - 実運用では tempfile.NamedTemporaryFile の利用がより安全。\n",
    "        key = item.get(key_name)  # ユニークキー（例: app_id）\n",
    "        filename = str(key) + \".json\"  # 例: \"123.json\"\n",
    "        f = open(\n",
    "            filename, \"w\"\n",
    "        )  # encoding を指定しないと環境依存（UTF-8 明示が望ましい）\n",
    "        json.dump(\n",
    "            item, f\n",
    "        )  # 日本語をエスケープせず保存: json.dump(item, f, ensure_ascii=False)\n",
    "        f.close()\n",
    "\n",
    "        # 3) コレクション処理状況の監視（バックプレッシャ制御）\n",
    "        #    - processing 中のドキュメント数が多い間は待機して API への過負荷を回避。\n",
    "        #    - この待機は「到着率 > 処理率」のときのキュー蓄積（待ち行列理論でいう M/M/1 等）を\n",
    "        #      緩和する実装方針に準ずる。\n",
    "        collection = discovery.get_collection(\n",
    "            environment_id, collection_id\n",
    "        ).get_result()\n",
    "        proc_docs = collection[\"document_counts\"][\"processing\"]\n",
    "\n",
    "        while True:\n",
    "            if proc_docs < 20:\n",
    "                # 閾値未満 → 送信継続\n",
    "                break\n",
    "            print(\"busy. waiting..\")\n",
    "            time.sleep(10)  # ポーリング間隔。API 制限と応答遅延を見て適宜調整。\n",
    "\n",
    "            # ※注意: 再取得時も `.get_result()` が必要（付け忘れると dict ではなく DetailedResponse になる）\n",
    "            collection = discovery.get_collection(\n",
    "                environment_id, collection_id\n",
    "            ).get_result()  # ← .get_result() を明示\n",
    "            proc_docs = collection[\"document_counts\"][\"processing\"]\n",
    "\n",
    "        # 4) JSON ファイルを Discovery にアップロード\n",
    "        #    - ファイルハンドルは with 文で安全にクローズ。\n",
    "        #    - add_document の戻り値（add_doc）は必要に応じてログ出力/ID 保持する。\n",
    "        with open(filename) as f:\n",
    "            add_doc = discovery.add_document(environment_id, collection_id, file=f)\n",
    "            # ここで add_doc.get_result() を呼び、document_id や status をログするのも有用。\n",
    "\n",
    "        # 5) 一時ファイルを削除（クリーンアップ）\n",
    "        os.remove(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b3a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特定のコレクションの全文書を削除する関数\n",
    "# collection_id: 対象コレクション\n",
    "\n",
    "\n",
    "def delete_all_docs(collection_id):\n",
    "\n",
    "    # 文書件数取得\n",
    "    collection = discovery.get_collection(environment_id, collection_id).get_result()\n",
    "    doc_count = collection[\"document_counts\"][\"available\"]\n",
    "\n",
    "    results = discovery.query(\n",
    "        environment_id, collection_id, return_fields=\"id\", count=doc_count\n",
    "    ).get_result()[\"results\"]\n",
    "    ids = [item[\"id\"] for item in results]\n",
    "\n",
    "    for id in ids:\n",
    "        print(\"deleting doc: id =\" + id)\n",
    "        discovery.delete_document(environment_id, collection_id, id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fbcc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 既存文書の全削除\n",
    "delete_all_docs(collection_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741de3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wikipedia文書のロード\n",
    "load_text(collection_id, data_list, \"app_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5548ae3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.6.14\n",
    "# 定山渓温泉の id 値（Discovery が付与する内部ドキュメントID）を調べる\n",
    "#\n",
    "# ポイント:\n",
    "# - `filter` はスコアリングに影響しない絞り込み（構造化）用の条件。高速で、結果の関連度は問わない。\n",
    "# - ここでは title フィールドが「定山渓温泉」に一致する文書だけを取り出し、その最初の1件の `id` を取得する。\n",
    "# - 取得する `id` は Discovery 内部のドキュメントIDであり、アプリ側で付与した `app_id` とは別物。\n",
    "# - `return_fields` で返却フィールドを絞ると転送量・処理負荷を抑えられる（ここでは確認用に app_id と title のみ）。\n",
    "#\n",
    "# 注意点:\n",
    "# - 文字列比較の安定性を高めるには、値を引用符で囲むのが無難（例: title::\"定山渓温泉\"）。\n",
    "#   日本語や空白・記号を含む場合は特に推奨。\n",
    "# - 一致する文書が0件のとき `query_results[0]` は例外になるため、実運用では件数チェックを行うこと。\n",
    "#   例:\n",
    "#     if not query_results:\n",
    "#         raise ValueError(\"対象文書が見つかりませんでした\")\n",
    "#\n",
    "# 返却フィールドの指定（app_id と title のみ返す）\n",
    "return_fields = \"app_id,title\"\n",
    "\n",
    "# フィルタ条件（title が「定山渓温泉」に一致）\n",
    "# ※ より安全にするなら: filter_text = 'title::\"定山渓温泉\"'\n",
    "filter_text = \"title::定山渓温泉\"\n",
    "\n",
    "# 照会の実行:\n",
    "# - `environment_id`, `collection_id`, `discovery` は事前に初期化済みである前提\n",
    "# - `filter` は構造化フィルタ、`return_fields` は返却項目を制限\n",
    "query_results = discovery.query(\n",
    "    environment_id, collection_id, filter=filter_text, return_fields=return_fields\n",
    ").get_result()[\"results\"]\n",
    "\n",
    "# 先頭ヒットの内部ドキュメントIDを取得\n",
    "# （ヒット順はスコアに依存しないため、確定的な選択が必要なら別途 sort 指定や追加条件を検討）\n",
    "similar_document_id = query_results[0][\"id\"]\n",
    "\n",
    "# 出力（確認用）\n",
    "print(similar_document_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a16750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リスト 4.6.15\n",
    "# 類似検索と結果表示\n",
    "#\n",
    "# 目的:\n",
    "# - 直前に特定した seed 文書（similar_document_id）に「似ている」文書を\n",
    "#   IBM Watson Discovery の Similar Documents 機能で検索し、\n",
    "#   各ヒットの app_id, title, スコア（類似度に基づく関連度）を表示する。\n",
    "#\n",
    "# 重要な前提:\n",
    "# - `environment_id`, `collection_id`, `discovery` は 4.6.1〜4.6.3 で初期化済み。\n",
    "# - `similar_document_id` は 4.6.14 で取得済み（コレクション内の内部ドキュメントID）。\n",
    "# - コレクションには十分な文書がロードされ、インデクシングが完了していること。\n",
    "\n",
    "# --- 類似検索の実施 ----------------------------------------------------------\n",
    "# Discovery V1 の query API に以下を指定:\n",
    "# - similar: 'true' を指定すると Similar Documents（既存文書に近い文書の検索）モードになる。\n",
    "#   * SDK 的には bool の True でも可（例: similar=True）。ここでは元コードに合わせ 'true' を使用。\n",
    "# - similar_document_ids: 類似度の基準とする seed 文書の内部 ID（配列も可だが、ここでは 1 件）。\n",
    "# - 必要に応じて `similar_fields` で比較対象フィールド（例: 'text,title'）を明示できる。\n",
    "#   未指定時はコレクション設定・マッピングに依存してテキストが比較される想定。\n",
    "simular_results = discovery.query(\n",
    "    environment_id,\n",
    "    collection_id,\n",
    "    similar=\"true\",  # 類似文書検索を有効化（bool の True でも可）\n",
    "    similar_document_ids=similar_document_id,  # 基準となる seed 文書 ID（文字列）\n",
    ")\n",
    "\n",
    "# レスポンス本体を取得\n",
    "res = simular_results.get_result()\n",
    "\n",
    "# 実際のヒット配列（`results`）を取り出す\n",
    "# - 各要素はインデックスに保存したフィールド（app_id, title, text など）と\n",
    "#   メタ情報（result_metadata）を含む辞書。\n",
    "res2 = res[\"results\"]\n",
    "\n",
    "# --- 結果表示 ---------------------------------------------------------------\n",
    "# 出力するのは:\n",
    "# - app_id: 4.3/3.5 節系で投入したアプリ側の一意キー（Discovery 内部 id とは別）。\n",
    "# - title: 文書タイトル。\n",
    "# - score: result_metadata.score。類似度由来の関連度スコア（高いほど seed に近い）。\n",
    "#\n",
    "# 注意:\n",
    "# - `score` は相対的指標で、閾値はユースケースに応じて調整が必要。\n",
    "# - app_id や title は投入時のマッピング/データに依存するため、欠損時 KeyError となる。\n",
    "#   本番では `item.get('app_id')` のように堅牢化するのが望ましい。\n",
    "for item in res2:\n",
    "    metadata = item[\"result_metadata\"]  # 検索メタ情報（score など）を持つ\n",
    "    score = metadata[\"score\"]  # 類似度ベースの関連度スコア（float）\n",
    "    app_id = item[\"app_id\"]  # アプリ側で付与した一意キー（登録データ由来）\n",
    "    title = item[\"title\"]  # 文書タイトル（登録データ由来）\n",
    "    print(app_id, title, score)\n",
    "\n",
    "# --- 実運用の補足 -----------------------------------------------------------\n",
    "# - 結果件数の制御: query(count=K) を追加指定してヒット数を調整。\n",
    "# - フィルタ併用: similar と同時に filter= を使ってドメイン・期間・種別などで絞り込み可能。\n",
    "# - 重複排除: deduplicate=True や deduplicate_field= を指定して近似重複を除去。\n",
    "# - ページング: offset/sort の組み合わせで安定した反復取得を行う。\n",
    "# - 監査/再現性: seed 文書 ID とパラメータ（similar_fields, filter など）を必ずログに残す。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
